{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sens_spec(y,pred):\n",
    "    tp = np.sum(np.logical_and(y,pred==y))\n",
    "    tn = np.sum(np.logical_and(1-y,pred==y))\n",
    "    fp = np.sum(np.logical_and(pred,pred!=y))\n",
    "    fn = np.sum(np.logical_and(1-pred,pred!=y))\n",
    "    \n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    prec = tp/(tp+fp)\n",
    "    return [sens,spec,acc,prec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = pd.read_csv(\"./Data/OHE_Eth.csv\").iloc[:,1:17].to_numpy()\n",
    "y = pd.read_csv(\"./Data/OHE_Eth.csv\")[\"OverallPoF\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "x_sp = np.arange(0,16)\n",
    "cs=CubicSpline(x_sp,X_raw,axis=1)\n",
    "X_in = cs(x_sp,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = (4, 5, 10, 13)\n",
    "i1 = [9]\n",
    "\n",
    "X = X_in[:,inds]\n",
    "X = np.hstack((X,X_raw[:,i1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "rs = 646\n",
    "tr,t = train_test_split([a for a in range(y.shape[0])],train_size=0.95,random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_ss(curve):\n",
    "    fpr = curve[0]\n",
    "    tpr = curve[1]\n",
    "    if tpr == 0:\n",
    "        return 0\n",
    "    if fpr ==0:\n",
    "        return 0\n",
    "    sigm = np.sum([1/fpr,1/tpr])\n",
    "    return 2/sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_cv_scores(cv_results_):\n",
    "    nsplits = 116#len(tr)\n",
    "    nparams = len(cv_results_['params'])\n",
    "    \n",
    "    senames = [\"split\"+str(a)+\"_test_sens\" for a in range(nsplits)]\n",
    "    spnames = [\"split\"+str(a)+\"_test_spec\" for a in range(nsplits)]\n",
    "    vlnames = [\"split\"+str(a)+\"_test_vals\" for a in range(nsplits)]\n",
    "    \n",
    "    scores = []\n",
    "    for a in range(nparams):\n",
    "        in_score = []\n",
    "        for b in range(nsplits):\n",
    "            s1 = int(cv_results_[senames[b]][a])\n",
    "            s2 = int(cv_results_[spnames[b]][a])\n",
    "            s3 = int(cv_results_[vlnames[b]][a])\n",
    "            in_score.append([s1,s2,s3])\n",
    "        scores.append(in_score)\n",
    "    scores=np.array(scores)\n",
    "    \n",
    "    rss = []\n",
    "    scs = []\n",
    "    for a in range(len(scores)):\n",
    "        ps = scores[a][:,2].astype(bool)\n",
    "        ns = np.invert(ps)\n",
    "        sens = np.mean(scores[a][ps][:,0])\n",
    "        spec = np.mean(scores[a][ns][:,1])\n",
    "        scs.append([sens,spec])\n",
    "        c_rss = rec_ss([sens,spec])\n",
    "        rss.append(c_rss)\n",
    "    ind = np.argmax(rss)\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def spec_func(y_true,y_pred):\n",
    "    s = np.mean(np.invert(y_true.astype(bool)) & np.invert(y_pred.astype(bool)))\n",
    "    return s\n",
    "def sens_func(y_true,y_pred):\n",
    "    s = np.mean(y_true.astype(bool) & y_pred.astype(bool))\n",
    "    return s\n",
    "def vals_func(y_true,y_pred):\n",
    "    return np.mean(y_true)\n",
    "\n",
    "spec_scorer = make_scorer(spec_func)\n",
    "sens_scorer = make_scorer(sens_func)\n",
    "vals_scorer = make_scorer(vals_func)\n",
    "\n",
    "multi_score={\n",
    "    'sens':sens_scorer,\n",
    "    'spec':spec_scorer,\n",
    "    'vals':vals_scorer\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"max_depth\":[1,2,3,4,5,6],\n",
    "    \"max_features\":[1,2,3,4,5],\n",
    "    \"class_weight\":['balanced'],\n",
    "    \"max_leaf_nodes\":[2,3,4,5,6,7,8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\",category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8055555555555556, 0.7643979057591623, 0.7709251101321586, 0.3918918918918919]\n",
      "[0.5, 0.8, 0.75, 0.3333333333333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "clf = GridSearchCV(dtc,params,scoring=multi_score,cv=LeaveOneOut(),refit=compare_cv_scores)\n",
    "clf.fit(X_raw[tr],y[tr])\n",
    "print(get_sens_spec(y[tr],clf.predict(X_raw[tr])))\n",
    "print(get_sens_spec(y[t],clf.predict(X_raw[t])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8611111111111112, 0.7905759162303665, 0.801762114537445, 0.43661971830985913]\n",
      "[0.5, 0.8, 0.75, 0.3333333333333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "clf = GridSearchCV(dtc,params,scoring=multi_score,cv=LeaveOneOut(),refit=compare_cv_scores)\n",
    "clf.fit(X[tr],y[tr])\n",
    "print(get_sens_spec(y[tr],clf.predict(X[tr])))\n",
    "print(get_sens_spec(y[t],clf.predict(X[t])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
